# Setup

```julia
using Bigleaf
using DataFrames

using Latexify
using DataDeps, Suppressor
using RData
import CodecBzip2, CodecXz
#@suppress_err # error in github-actions: GitHubActionsLogger has no field stream
register(DataDep(
    "DE_Tha_Jun_2014.rda",
    "downloading exampple dataset DE_Tha_Jun_2014 from bitbucket.org/juergenknauer/bigleaf",
    "https://bitbucket.org/juergenknauer/bigleaf/raw/0ebe11626b4409305951e8add9f6436703c82584/data/DE_Tha_Jun_2014.rda",
    "395f02e1a1a2d175ac7499c200d9d48b1cb58ff4755dfd2d7fe96fd18258d73c"
))
#println(datadep"DE_Tha_Jun_2014.rda")
ENV["DATADEPS_ALWAYS_ACCEPT"]="true" # avoid question to download
DE_Tha_Jun_2014 = first(values(load(joinpath(datadep"DE_Tha_Jun_2014.rda/DE_Tha_Jun_2014.rda"))))
tha = DE_Tha_Jun_2014
set_datetime_ydh!(tha)
thal = (
     LAI = 7.6,   # leaf area index
     zh  = 26.5,  # average vegetation height (m)
     zr  = 42,    # sensor height (m)
     Dl  = 0.01,  # leaf characteristic dimension (m)
)
```

## Data filtering

For most applications it is meaningful to filter your data. There are two main reasons 
why we want to filter our data before we start calculating ecosystem properties. 
The first one is to exclude datapoints that do not fulfill the requirements of the 
EC technique or that are of bad quality due to e.g. instrument failure or gap-filling 
with poor confidence. Note that the quality assessment of the EC data is not the purpose 
of the `Bigleaf.jl` package. This is done by other packages (e.g. `REddyProc`), 
which often provide quality control flags for the variables. These quality control 
flags are used here to filter out bad-quality datapoints.

A second reason for filtering our data is that some derived properties are only 
meaningful if certain meteorological conditions are met. For instance, if we are 
interested in properties related to plant gas exchange, it makes most sense to focus on 
time periods when plants are photosynthetically active 
(i.e. in the growing season and at daytime).

`Bigleaf.jl` provides methods that update (or create) the :valid column in 
a DataFrame. Records, i.e. rows, that contain non valid conditions are set to false.
If the valid column was false before, it stays at false.

One can check quality flags. By default (argument `setvalmissing = true`) this also
replaces the non-valid values in the data-columns by `missing`.
```julia
thaf = copy(tha)   # keep the original tha DataFrame
# if the :valid columns does not exist yet, it is created with all values true
setinvalid_qualityflag!(thaf; vars = ["LE", "NEE"])
sum(.!thaf.valid) # 7 records marked non-valid
sum(ismissing.(thaf.NEE)) # 7 NEE values set to missing
```
In the function call above, `vars` lists the variables that should be filtered with 
respect to their quality. Optional parameter `qc_suffix="_qc"` denotes the extension 
of the variable name that identifies the column as a quality control indicator of a given 
variable. The variables "LE" and "LE_qc", for example, denote the variable itself 
(latent heat flux), and the quality of the variable "LE", respectively. The optional 
argument `good_quality_threshold = 1.0` specifies the values of the quality column
below which the quality control to be considered as acceptable quality 
(i.e. to not be filtered). For example with default value 1, 
all "LE" values whose "LE_qc" variable is larger than 1 are set to `missing`. 
The variable `missing_qc_as_bad` is required to decide what to do in 
case of missing values in the quality control variable. By default this is (conservatively) 
set to `true`, i.e. all entries where the qc variable is missing is set invalid. 

We can  filter for meteorological conditions to be in acceptable ranges. 
For each variable to check we supply the valid minimum and valid maxium as a two-tuple
as the second component of a pair. If their is no limit towards small or
large values, supply `-Inf` or `Inf` as the minimum or maximum respectively.
```julia
setinvalid_range!(thaf, 
     :PPFD => (200, Inf), 
     :ustar => (0.2, Inf), 
     :LE =>(0, Inf), 
     :VPD => (0.01, Inf)
     )
sum(.!thaf.valid) # many more records marked invalid
minimum(skipmissing(thaf.PPFD)) >= 200 # values outsides range some set to missing
sum(ismissing.(thaf.PPFD)
```

About half of the data were filtered because radiation was not high enough (night-time). 
Another quarter was filtered because they showed negative LE values. 
However, most of them occured during the night:
```julia
sum(ismissing.(thaf.PPFD)) / nrow(thaf)
sum(.!ismissing.(thaf.PPFD) .&& ismissing.(thaf.LE)) / nrow(thaf)
```

A third method filters periods outside the growing season:
```julia
setinvalid_nongrowingseason!(thaf, 0.4) 
sum(.!thaf2.valid) # tha dataset is all within growing season - no additional invalids
```

This function implements a simple growing season filter based on daily smoothed GPP time 
series. 
Arguments  `tGPP` determines how high daily GPP has to be in relation to its peak value 
within the year. In this case, the value of 0.4 denotes that smoothed GPP has to be at 
least 40% of the 95th quantile. 
Argument `ws` controls the degree of smoothing in the timeseries 
and should be between 10-20 days. 
The purpose of which is to minimize the high variation of GPP between days,
Argument `min_int` is a parameter that avoids that data are switching from 
inside the growing season and out from one day to the next. 
It determines the minimum number of days that a season should have. 
The growing season filter is applicable to all sites, with one more more growing seasons,
but its advisable that site-specific parameter settings are used.

In this example, it does not really make sense to filter for growing season, 
since it uses only one month of data of which we know that vegetation is active at the site. 
The algorithm realizes that and does not mark any additional data as invalid.


As a last step we will filter for precipitation events. 
This is often meaningful for ecophysiological studies because data during and shortly 
after rainfall events do not contain much information on the physiological activity 
of the vegetation because they comprise significant fractions of evaporation from the 
soil and plant surfaces. The purpose of such a filter is mostly to minimize the fraction 
of soil and interception evaporation on the total water flux. This filter simply excludes 
periods following a precipitation event. A precipitation event, here, is defined as any time 
step with a recorded precipitation higher than `min_precip` (in mm per timestep). 
The function then filters all time periods following a precipitation event. 
The number of subsequent time periods excluded is controlled by the argument `precip_hours`. 
Here, we exclude rainfall events and the following 24 hours.
The timestamps in the DataFrame must be sorted in increasing order.

```julia
setinvalid_afterprecip!(thaf; min_precip=0.02, hours_after=24)
sum(.!thaf.valid) # some more invalids
```


When looking at the function output we see that we these settings, we exclude in total 1013 data points (70.35% of the data). In total, 29.65% of all data remained. The output of the `filter_data` function is another DataFrame (thaf), in which all filtered timesteps are set to missing. (Note that this is the default case. If we add `filtered_data_to_NA=true`, the data are left untouched, but an additional column "valid" is added to the DataFrame that specifies whether the time points fulfull the criteria or not). In the following examples we will work mostly with the filtered DataFrame `thaf`.










## Aerodynamic conductance

An important metric for many calculations in the `Bigleaf.jl` package is the aerodynamic conductance ($G_a$) between the land surface and the measurement height. $G_a$ characterizes how efficiently mass and energy is transferred between the land surface and the atmosphere. $G_a$ consists of two parts: $G_{am}$, the aerodynamic conductance for momentum, and $G_b$, the canopy boundary layer (or quasi-laminar) conductance. $G_a$ can be defined as $G_a = 1/(1/G_{am} + 1/G_b)$. In this tutorial we will focus on how to use the function `aerodynamic_conductance`. For further details on the equations, the reader is directed to the publication of the Bigleaf package (Knauer et al. 2018) and the references therein. A good overview is provided by e.g. Verma 1989.

$G_a$ and in particular $G_b$ can be calculated with varying degrees of complexity. We start with the simplest version, in which $G_b$ is calculated empirically based on the friction velocity ($u_*$) according to Thom 1972:

```julia
summary(aerodynamic_conductance(thaf))
```

Note that by not providing additional arguments, the default values are taken (type ?aerodynamic_conductance to see default values of the function arguments). We also do not need most of the arguments that can be provided to the function in this case (i.e. if `Rb_model=Val(:Thom_1972)`). These are only required if we use a more complex formulation of $G_b$.
The output of the function is another DataFrame which contains separate columns for conductances and resistances of different scalars (momentum, heat, and CO$_2$ by default).
For comparison, we now calculate a second estimate of $G_a$, where the calculation of $G_b$ is more physically-based (Su et al. 2001), and which requires more input variables compared to the first version. In particular, we now need LAI, the leaf characteristic dimension ($D_l$, assumed to be 1cm here), and information on sensor and canopy height ($z_r$ and $z_h$), as well as the displacement height (assumed to be 0.7*$z_h$):


```julia
Ga_Su = aerodynamic_conductance(thaf,Rb_model=Val(:Su_2001),LAI=thal.zh,zh= thal.zh,d=0.7*zh,
                                 zr= thal.zr,Dl=thal.Dl)
summary(Ga_Su)
thaf = cbind(thaf,Ga_Su)
```

We add the output of this function (`Ga_Su`) to our dataframe `thaf`. We see that the values are different compared to the first, empirical estimate. This is because this formulation takes additional aerodynamically relevant properties (LAI, $D_l$) into account that were not considered by the simple empirical formulation.




## Surface conditions

When we have an estimate of $G_a$, we are able to infer surface conditions of temperature and atmospheric humidity by inverting the bulk transfer relations of the sensible and latent heat fluxes. E_g. for temperature we can solve the following relation for $T_s$, the aerodynamic surface temperature:

  $T_a = T_s - \frac{H}{(\rho \cdot G_{ah} \cdot c_p)}$

where $T_a$ is air temperature, $H$ is the sensible heat flux ($\text{W m}^{-2}$) $\rho$ is air density ($\text{kg m}^{-3}$), $G_{\text{ah}}$ is the aerodynamic conductance for heat ($\text{m s}^{-1}$), and $c_p$ is the specific heat of air ($\text{J K}^{-1} \text{kg}^{-1}$). 
In `Bigleaf.jl`, the following function calculates conditions at the big-leaf surface:

```julia
surf = surface_conditions(thaf,calc_surface_CO2=true)
summary(surf)
thaf = cbind(thaf,surf)
```

By default, the function calculates surface temperature and several humidity measures, including VPD and relative humidity. If we set `calc_surface_CO2=true`, the CO$_2$ concentration at the surface is calculated additionally. Useful to know is that the expression "surface" depends on what kind of aerodynamic conductance we provide. If $G_a = G_{ah}$, we derive the conditions at the notional canopy surface (or the "big-leaf" surface). If $G_a = G_{am}$, we derive conditions in the intercanopy airspace (because $G_a$ does not account for the leaf boundary layer).

We can compare the surface and air temperature:

```julia
par(mfrow=c(1,2),mar=c(5,4,2,0.5))
plot(thaf[,"Tair"] ~ thaf[,"Tsurf"],xlim=c(8,35),ylim=c(8,35),las=1,
     xlab="Tsurf (degC)",ylab="Tair (degC)",mgp=c(2.2,0.5,0),tcl=-0.2)
abline(0,1)
plot(thaf[,"VPD"] ~ thaf[,"VPD_surf"],xlim=c(0,4),ylim=c(0,4),las=1,
     xlab="VPD surface (kPa)",ylab="VPD air (kPa)",mgp=c(2.2,0.5,0),tcl=-0.2)
abline(0,1)
```
Both surface temperature and VPD are in most cases higher than the ones measured at tower height.  




## Surface conductance

Knowledge on $G_a$ allows us to calculate the bulk surface conductance ($G_s$) of the site (In this case by inverting the Penman-Monteith equation). Gs represents the combined conductance of the vegetation and the soil to water vapor transfer (and as such it is not a purely physiological quantity). Calculating $G_s$ in `Bigleaf.jl` is simple:

```julia
summary(surface_conductance(thaf))
```
The function output is another DataFrame with two columns which only differ in the unit of $G_s$ (i.e. a hopeless attempt to make both physicists and physiologists happy). One in m s$^{-1}$ and one in mol m$^{-2}$ s$^{-1}$. In this function we have ignored the ground heat flux ($G$) and the storage fluxes ($S$), and the function politely reminds us of this omission by printing the first two lines of the output (it also tells us what it does, it assumes they are 0 in each time step). In this case we do not have information on the storage fluxes, but we have measurements on the ground heat flux, which we should add to the function call:

```julia
Gs = surface_conductance(thaf,G="G")
summary(Gs)
thaf = cbind(thaf,Gs)
```

Again, we have added the two output columns to our DataFrame `thaf`.









## Stomatal slope parameter

With both $G_s$ and $G_a$ available, we can estimate the stomatal slope parameter $g_1$. The $g_1$ parameter characterizes the slope between the surface conductance and the gross carbon uptake (GPP) of the ecosystem, and is thus strongly related to the ecosystem-level intrinsic water-use efficiency. However, it corrects for the confounding effects of VPD and $C_a$, and is thus better comparable across sites than e.g. GPP/$G_s$. 

```julia
## stomatal slope from the USO model (Medlyn et al. 2011)
g1_USO = stomatal_slope(thaf,model="USO",g0=0,robust_nls=true)
g1_USO
```

In this case, we have estimated $g_1$ from the USO (optimal stomatal optimization) model as described in Medlyn et al. 2011. The output is a model object that prints the model formulat that is used to estimate $g_1$, the estimated parameter value(s), as well as the weighted residual sum-of-squares. Further information on this model object can be obtained using the `summary` function.
In this case we have fixed the model intercept $g_0$ to 0 (this could also be any other value). We can also try to estimate $g_1$ and $g_0$ simultaneously (if we add `fitg0=true` to the function call above), but note that the two parameters are usually correlated, and that the values of $g_0$ are not straightforward to interpret (especially at ecosystem level). The option `robust_nls=true` specifies that $g_1$ is determined by a robust non-linear regression routine (from the `robustbase` package). We recommend to use this option since otherwise the parameter estimates are sensitive to outliers in $G_s$, which often occur even in filtered EC datasets.
By default, the model takes VPD and atmospheric CO$_2$ concentration as measured at the tower as input. We can also calculate $g_1$ by taking the surface conditions, which are probably more relevant for plant physiological processes than those measured a certain distance above the canopy:

```julia
## stomatal slope from the USO model (Medlyn et al. 2011)
stomatal_slope(thaf,Tair="Tsurf",VPD="VPD_surf",Ca="Ca_surf",model="USO",
               g0=0,robust_nls=true)
```
which in this case, does not change our $g_1$ value significantly.

We can also calculate $g_1$ using two different models. One is the long-standing Ball & Berry model (Ball et al. 1987), and the other one is a modification of the Ball & Berry model suggested by Leuning 1995:

```julia
## Ball&Berry slope
stomatal_slope(thaf,model="Ball&Berry",g0=0,robust_nls=true)
```
```julia
## Leuning slope
stomatal_slope(thaf,model="Leuning",g0=0,fitD0=true,robust_nls=true)
```

Note that the absolute value of the $g_1$ parameter depends on the model. In the Leuning model, we have a third parameter $D_0$ that can again either be estimated (as in the example above) or fixed to a pre-defined value (by default 1.5 kPa). $D_0$ describes the stomatal sensitivity to VPD (higher values correspond to a lower stomatal sensitivity to VPD - note however that $g_1$ and $D_0$ are strongly correlated, which makes an independent estimates of $D_0$ difficult to achieve). 

We can visualize the $g_1$ parameter by plotting $G_s$ against the "stomatal index":

```julia
stomatal_index = thaf[,"GPP"] / (thaf[,"Ca"] * sqrt(thaf[,"VPD"]))

plot(thaf[,"Gs_mol"] ~ stomatal_index,las=1,
     xlab=expression("GPP / (C"["a"]~sqrt("D"["a"])*")"),
     ylab=expression("G"["sw"]~"(mol m"^{-2}~"s"^{-1}*")"),
     tcl=0.2,mgp=c(2.2,0.5,0),xlim=c(0,0.12))
```



## Wind profile

The 'big-leaf' framework assumes that wind speed is zero at height d + $z_{0m}$ (where $z_{0m}$ is the roughness length for momentum) and then increases exponentially with height. The shape of the wind profile further depends on the stability conditions of the air above the canopy.
In `Bigleaf.jl`, a wind profile can be calculated assuming an exponential increase with height, which is affected by atmospheric stability. Here, we calculate wind speed at heights of 22-60m in steps of 2m. As expected, the gradient in wind speed is strongest close to the surface and weaker at greater heights:

```julia
using Statistics
wind_heights = 22:2:60.0
d = 0.7 * thal.zh
#psi_m = stability_correction!(copy(tha, copycols=false), thal.zr, d).psi_m
#z0m = roughness_parameters(Val(:wind_profile), tha, thal.zh, thal.zr; psi_m).z0m
wp = map(wind_heights) do z
  wind_profile(tha,z,d; zh=thal.zh, zr=thal.zr)
end
wp_means = map(x -> mean(skipmissing(x)), wp)
wp_sd    = map(x -> std(skipmissing(x)), wp)
wr_mean = mean(skipmissing(tha.wind)) # measurements at reference height
wr_sd    = std(skipmissing(tha.wind))

using Plots # plot wind profiles for the three rows in df
plot(wp_means, wind_heights, ylab = "height (m)", xlab = "wind speed (m/s)", xerror=wp_sd, label=nothing)
scatter!(wp_means, wind_heights, label = nothing)
scatter!([wr_mean], [thal.zr], xerror = [wr_sd], markerstrokecolor=:blue, markerstrokewidth=2, label = nothing)
```
Here, the points denote the mean wind speed and the bars denote the standard deviation
across time. The blue point/bar represent the values that were measured at zr = 42m. 
In this case we see that the wind speed as "back-calculated" from the wind profile agrees 
well with the actual measurements.


## Potential evapotranspiration

For many hydrological applications, it is relevant to get an estimate on the potential 
evapotranspiration (PET). At the moment, the `Bigleaf.jl` contains two formulations 
for the estimate of PET: the Priestley-Taylor equation, and the Penman-Monteith equation:

```julia
potential_ET!(thaf, Val(:PriestleyTaylor); G = thaf.G, infoGS = false)
# TODO need surface conductance to compute Ga and Gs_mol before
# potential_ET!(thaf, Val(:PenmanMonteith);  G = thaf.G, 
#        Gs_pot=quantile(skipmissing(thaf.Gs_mol),0.95))
```

In the second calculation it is important to provide an estimate of aerodynamic 
conductance Ga and ``Gs_{pot}``, the potential surface conductance under optimal conditions. 
Here, we have approximated ``Gs_{pot}`` with the ``95^{\text{th}}`` percentile of all 
``G_s`` values of the site. 

## Energy balance closure (EBC)

The `Bigleaf.jl` package offers a function which characterizes the degree of the EBC (i.e. $A = \lambda E + H$, where A is available energy, $\lambda E$ is the latent heat flux, and H is the sensible heat flux, all in $\text{W m}^{-2}$). We can calculate the EBC with the following command:

```julia
energy_closure(tha)
```

The output tells us the number of observations that were used for the calculation of the EBC (n; note that we took the unfiltered DataFrame here), the intercept and slope of the LE + H ~ A plot, the $r^2$ of the regression, and the energy balance ratio (EBR = $\frac{\lambda E + H}{R_n - G -S}$). Thus, the degree of EBC is characterized by two metrics, the slope of the $\lambda E$ + H ~ A relationship, and the EBR. In this case they agree relatively well; both indicate a gap in the energy balance of ~ 30%. In the calculations above, we did not include the ground heat $G$ into the equation, which is the default setting (i.e. $A$ was assumed to equal $R_n$). We can now have a look to what extent the EBC improves when we consider G (i.e. $A = R_n - G$):

```julia
energy_closure(tha,G="G")
```

In this case the ground heat flux improves the EBC, but only marginally. This implies that there are other reasons for the EBC, including an underestimation of the turbulent fluxes. It should be clear, however, that this example is not representative for all EC sites. In general, $G$ is more important (and $S$ is less important) at sites with low biomass and short vegetation.





## Meteorological variables

The `Bigleaf.jl` package provides calculation routines for a number of meteorological variables, which are basic to the calculation of many other variables. A few examples on their usage are given below:

```julia
# Saturation vapor pressure (kPa) and slope of the saturation vapor pressure curve (kPa K-1)
Esat_slope(Tair=25)
```
```julia
# psychrometric constant (kPa K-1)
psychrometric_constant(Tair=25,pressure=100)
```
```julia
# air density (kg m-3)
air_density(Tair=25,pressure=100)
```
```julia
# dew point (degC)
dew_point(Tair=25,VPD=1)
```
```julia
# wetbulb temperature (degC)
wetbulb_temp(Tair=25,pressure=100,VPD=1)
```
```julia
# estimate atmospheric pressure from elevation (hypsometric equation)
pressure_from_elevation(elev=500,Tair=25)
```


## Unit interconversions

The package further provides a number of useful unit interconversions, which are straightforward to use (please make sure that the input variable is in the right unit, e.g. rH has to be between 0 and 1 and not in percent):

```julia
# VPD to vapor pressure (e, kPa)
VPD_to_e(VPD=2,Tair=25)
```
```julia
# vapor pressure to specific humidity (kg kg-1)
e_to_q(e=1,pressure=100)
```
```julia
# relative humidity to VPD (kPa)
rH_to_VPD(rH=0.6,Tair=25)
```
```julia
# conductance from ms-1 to mol m-2 s-1
ms_to_mol(G_ms=0.01,Tair=25,pressure=100)
```
```julia
# umol CO2 m-2 s-1 to g C m-2 d-1
umolCO2_to_gC(CO2_flux=20)
```


\vspace{1cm}

# Useful hints for advanced users


## Hide function messages

As shown earlier in this tutorial, many functions of the `Bigleaf.jl` package print messages to make the reader aware that e.g. some flux components are missing. This output can be a bit annoying when functions are used in loops or `apply`-functions. A simple way to not show these messages is to use a combination of `invisible` and `capture_output`:

```julia
## instead of 
PET = potential_ET(Tair=25,pressure=100,Rn=200)
## one can use
invisible(capture_output(PET = potential_ET(Tair=25,pressure=100,Rn=200)))
```



## Constants

The `Bigleaf.jl` package contains a single list of constants (see `?Bigleaf_constants`). Whenever one or more constants are used in a function, this list is provided as a default argument, so the user does usually not need to interact with this list. However, should you wish to change a certain constant for the calculations (which could make sense in some cases, e.g. using a different value for the von-Karman constant (k)), individual constants can be changed within a function call. As an example, let's call a function with the `Bigleaf.jl` default value of k=0.41, and the alternative, often used value of k=0.4:

```julia
summary(aerodynamic_conductance(thaf,wind_profile=true,zr= thal.zr,d=0.7*zh,z0m=2.65)[,"Ga_h"])
summary(aerodynamic_conductance(thaf,wind_profile=true,zr= thal.zr,d=0.7*zh,z0m=2.65,
                                constants=Bigleaf_constants(k=0.4))[,"Ga_h"])
```

We see that in this case, small changes in k have an effect on the calculated values of $G_{ah}$, but they do not change the results significantly (however, the same value of k should be used for all calculations).



## Boundary layer conductance for trace gases

By default, the functions `aerodynamic_conductance` (calling `compute_Gb!`) returns the 
(quasi-laminar) canopy boundary layer ($G_{b}$) for heat and water vapor 
(which are assumed to be equal in the `Bigleaf.jl` package), as well as for CO$_2$. 
Functin `add_Gb` calculates $G_b$ for other trace gases, provided that the respective Schmidt 
number is known. 

```@example doc
compute_Gb!(thaf, Val(:Thom_1972)) # adds/modifies column Gb_h and Gb_CO2
add_Gb!(thaf, :Gb_O2 => 0.84, :Gb_CH4 => 0.99) # adds Gb_O2 and Gb_CH4
select(first(thaf,3), r"Gb_")
```


## Dealing with uncertainties

It is important to note that the `Bigleaf.jl` package does not calculate uncertainties of most variables. This is firstly because it is challenging to properly account for all the uncertainties present in EC data, and secondly because this would lead to much slower and more complex function calls. Nevertheless, uncertainties of the calculated ecosystem properties should not be ignored. Here, we present two main strategies on how to quantify uncertainties: 1) bootstrapping, and 2) Monte Carlo analysis. In general, we leave the calculations/function calls untouched, but we add wrapper functions that use different techniques (e.g. bootstrapping) to calculate uncertainties of the output variables.

### Bootstrapping

As a first example, we use bootstrapping to estimate the uncertainty of the $g_1$ parameter calculated above. The principle is easy: we calculate $g_1$ a given number of times (in this case 300 times), and each time we only use a (different) subset of the data. In each iteration, 25% of the data are discarded. To do this, we can define the following function (note that this function can be written in a more efficient way, but by using a loop the principle becomes clear):

```julia
G1_bootstrap = function(dat,LoopNum,SampSizeRel)
  # dat         = input DataFrame
  # LoopNum     = number of iterations
  # SampSizeRel = fraction of data sampled for each iteration
  dfout=DataFrame(matrix(missing,nrow = LoopNum,ncol = 0)) #Define output dataframe
  dat$RunNum=1:nrow(dat)
  SampSize=round(length(dat$RunNum)*SampSizeRel) #calculate number of data used for resampling

  for (m in 1:LoopNum)
    # sample data:
    SampIDX=sample(x = dat$RunNum,size = SampSize,replace = T) 
    # run the function on the sample data:
    dfout$G1[m]=summary(stomatal_slope(data = dat[SampIDX,],
                                       Tair = dat$Tair[SampIDX],
                                       Gs=dat$Gs_mol[SampIDX],
                                       pressure = dat$pressure[SampIDX],
                                       GPP = dat$GPP[SampIDX],
                                       VPD = dat$VPD[SampIDX],
                                       Ca = dat$Ca[SampIDX],
                       model="USO",g0=0,robust_nls=T))$coef[1,1] 
end

  return(dfout) # return output dataframe
end
```

We can use this function with our data:

```{r, results="hide"}
# 300 times resampling; each time 75 % of the data: 
tha_G1BT = G1_bootstrap(dat = thaf,LoopNum = 300,SampSizeRel = 0.75) 
# estimate using all data:
g1_mean = summary(g1_USO)$coef[1,1]
g1_se   = summary(g1_USO)$coef[1,2]

par(mar=c(2,6,1,1))
boxplot(tha_G1BT,ylab=expression(italic("g")["1,USO"]~"(kPa"^{0.5}*")"),las=1,mgp=c(2,0.5,0))
points(g1_mean,col="blue",pch=16,cex=1.5)
arrows(1,g1_mean - g1_se,1,g1_mean + g1_se,angle=90,length=0.2,code=3,col="blue",lwd=2)
```

The blue point shows the estimate (+/- standard error) when we take all data, as calculated above. The two estimates agree very well, indicating that in this case we can be very confident on the calculated $g_1$ estimate. The bootstrapping technique can also be applied to other (regression-based) functions in the package.




### Monte Carlo analysis

In the second example we implement a simple Monte Carlo analysis in which we propagate uncertainties in the calculation of $G_a$ to uncertainties in $G_s$ (which takes $G_a$ as input). To do this, we first estimate the uncertainty in $G_a$ that is caused by uncertainties in three of its input parameters: the leaf characteristic dimension $D_l$, the LAI, and the roughness length $z_{0m}$. The uncertainty of other parameters could be included, but for demonstration purposes we only use these three. 
First, we have to assess the mean and the error distribution of the input parameters. We estimated $D_l$ = 1cm, LAI=7.6 (as measured at the site), and $z_{0m}=2.65m$ (10% of the vegetation height), and we assume that their errors are normally distributed with a standard deviation (sd) equal to 25% of the mean in case of $z_{0m}$ and $D_l$. In case of LAI we assume a sd of 0.5. 

```julia
n_pert = 200
z0m1   = 2.65
Dl1    = 0.01
LAI1   = 7.6
z0m_sample = pmax(rnorm(n=n_pert,mean=z0m1,sd=0.25*z0m1),0)
Dl_sample  = pmax(rnorm(n=n_pert,mean=Dl1,sd=0.25*Dl1),0)
LAI_sample = rnorm(n=n_pert,mean=LAI1,sd=0.5)
```

In the example above we create a parameter space that we use for the subsequent calculations. We have chosen the most simple settings here, that means we assume that parameters have a normal error distribution and that they are independent of each other. In many cases these assumptions are not valid. For example, measured fluxes are more likely to have a Laplace error distribution (Hollinger & Richardson 2005), which would be better sampled using `rlaplace` from the `rmutil` package instead of `rnorm`. In many cases, the parameters are also not independent of each other. In our case, $z_{0m}$ and $D_l$ may not be strongly correlated, but one would possibly expect a correlation between LAI and $z_{0m}$. We can account for dependencies among variables by doing the sampling based on a variance-covariance matrix that prescribes correlations between variables.
 

```julia
unc_all = mapply(aerodynamic_conductance,Dl=Dl_sample,z0m=z0m_sample,LAI=LAI_sample,
                        MoreArgs=list(data=thaf,zr=42,zh=26.5,d=0.7*26.5,
                                      N=2,stab_correction=T,
                                      stab_formulation=Val(:Dyer_1970),
                                      Rb_model=Val(:Su_2001))
                  )

# select "Ga_h" output variable and convert to matrix
unc_Ga_h = matrix(unlist(unc_all["Ga_h",]),ncol=n_pert,byrow=false) 

# calculate 2.5th, 50th, and 97.5th quantile of the n_pert calculations for every timestep
Ga_low  = apply(unc_Ga_h,1,quantile,0.025,na_rm=T)
Ga_mean = apply(unc_Ga_h,1,quantile,0.5,na_rm=T)
Ga_high = apply(unc_Ga_h,1,quantile,0.975,na_rm=T)
Ga = cbind(Ga_low,Ga_mean,Ga_high)
summary(Ga)


# calculate the Gs for the three Ga estimates
Gs_low  = surface_conductance(thaf,Ga=Ga[,"Ga_low"],G="G")[,"Gs_mol"]
Gs_mean = surface_conductance(thaf,Ga=Ga[,"Ga_mean"],G="G")[,"Gs_mol"]
Gs_high = surface_conductance(thaf,Ga=Ga[,"Ga_high"],G="G")[,"Gs_mol"]
Gs = cbind(Gs_low,Gs_mean,Gs_high)
summary(Gs)
```
The first and the last columns of the output give us now an uncertainty envelope around our $G_a$ and $G_s$ calculations. The example shows that variations in the three input parameters are sensitive for the estimation of $G_a$, but not so much for $G_s$:


```julia
par(mfrow=c(1,2))
ind = c(1:48) # first day
plot(Ga_mean[ind],type="l",lwd=2,xlab="timestep",ylab=expression("G"["ah"]~"(m s"^{-1}*")"),
     las=1,mgp=c(2.2,0.5,0),tcl=-0.2,ylim=c(0.045,0.14))

ok = which(!ismissing(Ga_mean[ind]))
polygon(c(ok,rev(ok)),c(Ga_high[ind][ok],rev(Ga_low[ind][ok])),
        col="grey70",border=missing)
points(Ga_mean[ind],type="l",lwd=2)


plot(Gs_mean[ind],type="l",lwd=2,xlab="timestep",tcl=-0.2,
     ylab=expression("G"["sw"]~"(mol m"^{-2}~"s"^{-1}*")"),las=1,mgp=c(2.2,0.5,0))

ok = which(!ismissing(Gs_mean[ind]))
polygon(c(ok,rev(ok)),c(Gs_high[ind][ok],rev(Gs_low[ind][ok])),
        col="grey70",border=missing)
points(Gs_mean[ind],type="l",lwd=2)
```

In general, these operations are more effectively implemented elsewhere, and we just show an example for demonstration purposes. The reader might be interested in the `FME` package (in particular the `sensRange` function). The package also provides functions (e.g. `Norm`) that generates parameter sets based on a parameter variance-covariance matrix.



\vspace{1cm}


## References

Ball, J. T.; Woodrow, I. E. & Berry, J. A. Biggins, J. (Ed.) A model predicting stomatal conductance and its contribution to the control of photosynthesis under different environmental conditions Progress in photosynthesis research, Martinus Nijhoff Publishers, Dordrecht, Netherlands, 1987, 221-224.

Gr√ºnwald, T. & Bernhofer, C. A decade of carbon, water and energy flux measurements of an old spruce forest at the Anchor Station Tharandt Tellus B, Wiley Online Library, 2007, 59, 387-396.

Hollinger, D. & Richardson, A. Uncertainty in eddy covariance measurements and its application to physiological models. Tree physiology, 2005, 25, 873-885.

Knauer, J., El-Madany, T_S., Zaehle, S., Migliavacca, M. An R package for the calculation of physical and physiological ecosystem properties from eddy covariance data. PLoS ONE, 2018, e0201114.

Leuning, R. A critical appraisal of a combined stomatal-photosynthesis model for C3 plants Plant, Cell & Environment, Wiley Online Library, 1995, 18, 339-355.

Leuning, R.; Van Gorsel, E.; Massman, W. J. & Isaac, P. R. Reflections on the surface energy imbalance problem Agricultural and Forest Meteorology, 2012, 156, 65-74.

Medlyn, B. E.; Duursma, R. A.; Eamus, D.; Ellsworth, D. S.; Prentice, I. C.; Barton, C. V.; Crous, K. Y.; de Angelis, P.; Freeman, M. & Wingate, L. Reconciling the optimal and empirical approaches to modelling stomatal conductance. Global Change Biology, 2011, 17, 2134-2144.

Su, Z.; Schmugge, T.; Kustas, W. & Massman, W. An evaluation of two models for estimation of the roughness height for heat transfer between the land surface and the atmosphere. Journal of Applied Meteorology, 2001, 40, 1933-1951.

Thom, A. Momentum, mass and heat exchange of vegetation. Quarterly Journal of the Royal Meteorological Society, 1972, 98, 124-134.

Verma, S. Black, T.; Spittlehouse, D.; Novak, M. & Price, D. (Eds.) Aerodynamic resistances to transfers of heat, mass and momentum Estimation of areal evapotranspiration, Estimation of areal evapotranspiration, International Association of Hydrological Sciences, 1989, 177, 13-20.
